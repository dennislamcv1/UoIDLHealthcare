{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8ce1863275e6f7c9dd6bb1a85e9be673",
          "grade": false,
          "grade_id": "cell-c62a654b63bcc6a9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Lab 3\n",
        "\n",
        "In the previous labs, we perform mortality prediction based on the last visit's diagnosis codes using DNN. This practice igrnoes massive information in the previous visits of a patient. Thus, Starting from this lab, we will play with sequential visit data. That is, each patient will have a sequence of visists. \n",
        "\n",
        "However, MLP is quite unsatisfying when dealing with such rich structure data. This lab introduces convolutional neural networks (CNNs), a powerful family of neural networks that are designed for precisely this purpose.\n",
        "\n",
        "Table of Contents:\n",
        "- Convolutions for Images\n",
        "- Padding and Stride\n",
        "- Pooling\n",
        "- Assignment\n",
        "\n",
        "Some contents of this lab are adapted from [Dive into Deep Learning](https://d2l.ai) and [Official PyTorch Tutorials](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.132823Z",
          "start_time": "2021-12-10T04:02:11.129993Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4ec96802e337ce0700f6db56afa5efbc",
          "grade": false,
          "grade_id": "cell-6fb60e1a98394fe2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.138646Z",
          "start_time": "2021-12-10T04:02:11.135043Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6dfe8ed43a3f5980a3c92360d617e4e4",
          "grade": false,
          "grade_id": "cell-204b53e7b414910c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "seed = 24\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.261670Z",
          "start_time": "2021-12-10T04:02:11.140607Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a2d820e50d980d5cd85e747cee3ca331",
          "grade": false,
          "grade_id": "cell-120c0ecf94034038",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"../LAB3-lib/data\"\n",
        "assert os.path.isdir(DATA_PATH)\n",
        "!ls {DATA_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "96480855a5b84fd9eab5e0424029a4a2",
          "grade": false,
          "grade_id": "cell-e7a788c7628625ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 1. Convolution Operation\n",
        "\n",
        "Though we will deal with sequential data (1D) in the assignment. Let us first start with some images data (2D) to \n",
        "build out intuition. \n",
        "\n",
        "Convolutional neural networks are efficient architectures for exploring structure in image data.\n",
        "\n",
        "Convolution operation take an input tensor and a kernel tensor and produce an output tensor through convolution operation. Let us ignore channels for now and see how this works with two-dimensional data and hidden representations. In the figure below, the input is a two-dimensional tensor with a height of 3 and width of 3. We mark the shape of the tensor as 3x3 or (3, 3). The height and width of the kernel are both 2. The shape of the kernel window (or convolution window) is given by the height and width of the kernel (here it is 2x2).\n",
        "\n",
        "<img src='./img/convolution.svg'>\n",
        "\n",
        "In the two-dimensional cross-correlation operation, we begin with the convolution window positioned at the top-left corner of the input tensor and slide it across the input tensor, both from left to right and top to bottom. When the convolution window slides to a certain position, the input subtensor contained in that window and the kernel tensor are multiplied elementwise and the resulting tensor is summed up yielding a single scalar value. This result gives the value of the output tensor at the corresponding location. Here, the output tensor has a height of 2 and width of 2 and the four elements are derived from the two-dimensional cross-correlation operation:\n",
        "\n",
        "$$\n",
        "\\begin{split}0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
        "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
        "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
        "4\\times0+5\\times1+7\\times2+8\\times3=43.\\end{split}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d2b2a67dd4cbc81f69ba8f1589fbe4b1",
          "grade": false,
          "grade_id": "cell-4a73c276a3b5a068",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 1 [10 points]\n",
        "\n",
        "Calculate the output shape for a convolutional layer: given the input tensor shape $(n_w, n_h)$, the kernel tensor shape $(k_w, k_h)$, calculate the output tensor shape. For example, the output shape for the figure above is $(2, 2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.266735Z",
          "start_time": "2021-12-10T04:02:11.263685Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "def conv_output_shape_1(n_w, n_h, k_w, k_h):\n",
        "    \n",
        "    \"\"\"\n",
        "    TODO: Calculate the output tensor shape.\n",
        "    Note the output should a tuple with two elements (width, height). \n",
        "    \"\"\"\n",
        "    # your code here\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.272511Z",
          "start_time": "2021-12-10T04:02:11.269268Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9be534d4228b758bf0a84533777bd033",
          "grade": true,
          "grade_id": "cell-3cf0291efe3340a9",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "assert conv_output_shape_1(n_w=7, n_h=7, k_w=3, k_h=3) == (5, 5)\n",
        "assert conv_output_shape_1(n_w=7, n_h=9, k_w=4, k_h=2) == (4, 8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fe87a84e27bf38c181cf79c5723bb328",
          "grade": false,
          "grade_id": "cell-40d58ffd6353d1ae",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 2 [10 points]\n",
        "\n",
        "Implement the 2D convolution function, which accepts an input tensor X and a kernel tensor K and returns an output tensor Y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.277255Z",
          "start_time": "2021-12-10T04:02:11.273876Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "def corr2d(X, K):\n",
        "    \"\"\" TODO: Compute 2D convolution. \"\"\"\n",
        "    # your code here\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.283631Z",
          "start_time": "2021-12-10T04:02:11.278764Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed053dafa7288f5f34b317a80b275d64",
          "grade": true,
          "grade_id": "cell-00293bf4adfd6c5c",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "assert torch.allclose(corr2d(X, K), torch.tensor([[19., 25.], [37., 43.]]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cbd077f553c7f733074f8f2245c6a7a9",
          "grade": false,
          "grade_id": "cell-b2f57cdb1e9cb59d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2. Padding and Stride\n",
        "\n",
        "In several cases, we incorporate techniques, including padding and strided convolutions, that affect the size of the output. As motivation, note that since kernels generally have width and height greater than 1, after applying many successive convolutions, we tend to wind up with outputs that are considerably smaller than our input. If we start with a 240\u00d7240 pixel image, 10 layers of 5x5 convolutions reduce the image to 200\u00d7200 pixels, slicing off 30%\n",
        "of the image and with it obliterating any interesting information on the boundaries of the original image. Padding is the most popular tool for handling this issue.\n",
        "\n",
        "In other cases, we may want to reduce the dimensionality drastically, e.g., if we find the original input resolution to be unwieldy. Strided convolutions are a popular technique that can help in these instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "878e1aa494da4c400ae4ddee80b13fb4",
          "grade": false,
          "grade_id": "cell-e4cbe1af43117fca",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### 2.1 Padding\n",
        "\n",
        "As described above, one tricky issue when applying convolutional layers is that we tend to lose pixels on the perimeter of our image. Since we typically use small kernels, for any given convolution, we might only lose a few pixels, but this can add up as we apply many successive convolutional layers. One straightforward solution to this problem is to add extra pixels of filler around the boundary of our input image, thus increasing the effective size of the image. Typically, we set the values of the extra pixels to zero. In the figure below, we pad a 3\u00d73 input, increasing its size to 5\u00d75. The corresponding output then increases to a 4\u00d74 matrix. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: 0\u00d70+0\u00d71+0\u00d72+0\u00d73=0.\n",
        "\n",
        "<img src='./img/conv-pad.svg'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f49b6caecf632c4e1afd17f975733281",
          "grade": false,
          "grade_id": "cell-d953b18f84a624b2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### 2.2 Stride\n",
        "\n",
        "When computing the convolution, we start with the convolution window at the top-left corner of the input tensor, and then slide it over all locations both down and to the right. In previous examples, we default to sliding one element at a time. However, sometimes, either for computational efficiency or because we wish to downsample, we move our window more than one element at a time, skipping the intermediate locations.\n",
        "\n",
        "We refer to the number of rows and columns traversed per slide as the stride. So far, we have used strides of 1, both for height and width. Sometimes, we may want to use a larger stride. The figure below shows a two-dimensional convolution operation with a stride of 3 vertically and 2 horizontally. The shaded portions are the output elements as well as the input and kernel tensor elements used for the output computation:  0\u00d70+0\u00d71+1\u00d72+2\u00d73=8, 0\u00d70+6\u00d71+0\u00d72+0\u00d73=6. We can see that when the second element of the first column is outputted, the convolution window slides down three rows. The convolution window slides two columns to the right when the second element of the first row is outputted. When the convolution window continues to slide two columns to the right on the input, there is no output because the input element cannot fill the window (unless we add another column of padding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40e98bd48f6eaf8e751a54708de58594",
          "grade": false,
          "grade_id": "cell-9972bce032bdc90d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 3 [10 points]\n",
        "\n",
        "Calculate the output shape for a convolutional layer with padding: given the input tensor shape $(n_w, n_h)$, the kernel tensor shape $(k_w, k_h)$, padding size $(p_w, p_h)$, stride size $(s_w, s_h)$, calculate the output tensor shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.288359Z",
          "start_time": "2021-12-10T04:02:11.285281Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "def conv_output_shape_2(n_w, n_h, k_w, k_h, p_w, p_h, s_w, s_h):\n",
        "    \n",
        "    \"\"\"\n",
        "    TODO: Calculate the output tensor shape.\n",
        "    Note the output should a tuple with two elements (width, height). \n",
        "    \"\"\"\n",
        "    # your code here\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.294885Z",
          "start_time": "2021-12-10T04:02:11.290222Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d049a8cffa5a6188db350a0d4430212b",
          "grade": true,
          "grade_id": "cell-99a12d5208d4d7d6",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "assert conv_output_shape_2(n_w=7, n_h=7, k_w=3, k_h=3, p_w=1, p_h=1, s_w=1, s_h=1) == (7, 7)\n",
        "assert conv_output_shape_2(n_w=7, n_h=7, k_w=3, k_h=3, p_w=0, p_h=0, s_w=2, s_h=2) == (3, 3)\n",
        "assert conv_output_shape_2(n_w=7, n_h=9, k_w=4, k_h=2, p_w=0, p_h=1, s_w=2, s_h=1) == (2, 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eb11b5b6d5e666c3ec493a79440c1724",
          "grade": false,
          "grade_id": "cell-db2171adeaa11955",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3. Multiple Input and Multiple Output Channels\n",
        "\n",
        "Denote by $c_i$ and $c_o$ the number of input and output channels, respectively, and let $k_h$ and $k_w$ be the height and width of the kernel. To get an output with multiple channels, we can create a kernel tensor of shape $c_i \\times k_h \\times k_w$ for every output channel. We concatenate them on the output channel dimension, so that the shape of the convolution kernel is $c_o \\times c_i \\times k_h \\times k_w$. In convolution operations, the result on each output channel is calculated from the convolution kernel corresponding to that output channel and takes input from all channels in the input tensor.\n",
        "\n",
        "<img src='./img/conv-channel.svg'>\n",
        "\n",
        "In the figure above, the number of input and output channels are 3 and 2. And there are $2 \\times 3$ sets of kernels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b4c5e51b1cec69e0adec08a4692d96ad",
          "grade": false,
          "grade_id": "cell-d739af556c00535d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 4. Pooling\n",
        "\n",
        "Often, as we process images, we want to gradually reduce the spatial resolution of our hidden representations, aggregating information so that the higher up we go in the network, the larger the receptive field (in the input) to which each hidden node is sensitive.\n",
        "\n",
        "Like convolutional layers, pooling operators consist of a fixed-shape window that is slid over all regions in the input according to its stride, computing a single output for each location traversed by the fixed-shape window (sometimes known as the pooling window). However, unlike the cross-correlation computation of the inputs and kernels in the convolutional layer, the pooling layer contains no parameters (there is no kernel). Instead, pooling operators are deterministic, typically calculating either the maximum or the average value of the elements in the pooling window. These operations are called maximum pooling (max pooling for short) and average pooling, respectively.\n",
        "\n",
        "In both cases, as with the cross-correlation operator, we can think of the pooling window as starting from the upper-left of the input tensor and sliding across the input tensor from left to right and top to bottom. At each location that the pooling window hits, it computes the maximum or average value of the input subtensor in the window, depending on whether max or average pooling is employed.\n",
        "\n",
        "<img src='./img/pooling.svg'>\n",
        "\n",
        "The output tensor in the figure above has a height of 2 and a width of 2. The four elements are derived from the maximum value in each pooling window:\n",
        "\n",
        "$$\n",
        "\\begin{split}\\max(0, 1, 3, 4)=4,\\\\\n",
        "\\max(1, 2, 4, 5)=5,\\\\\n",
        "\\max(3, 4, 6, 7)=7,\\\\\n",
        "\\max(4, 5, 7, 8)=8.\\\\\\end{split}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f7ca267c604aaa00b16a086583f5d3d9",
          "grade": false,
          "grade_id": "cell-e873bdd6653b39c5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 4 [10 points]\n",
        "\n",
        "Implement a 2D max pooling layer from scratch, which accepts an input tensor X and pool size and returns an output tensor Y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.300692Z",
          "start_time": "2021-12-10T04:02:11.296927Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "def maxpool2d(X, pool_size):\n",
        "    # your code here\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.311880Z",
          "start_time": "2021-12-10T04:02:11.305965Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f35aa399e9044796e506ce2da9f6f971",
          "grade": true,
          "grade_id": "cell-ebbbed2cb92d5ff1",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "assert torch.allclose(maxpool2d(X, (2, 2)), torch.tensor([[4., 5.], [7., 8.]]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "39f2b33ec80d485d14046f1397484a1b",
          "grade": false,
          "grade_id": "cell-f6903ac912b48867",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5. CNN with PyTorch\n",
        "\n",
        "Luckily, PyTorch has all kinds of convolution and pooling operations implemented for us ([link](https://pytorch.org/docs/stable/nn.html#convolution-layers)). For the previous image example, we can use [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) and [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d).\n",
        "\n",
        "For example, the code below implements a 2D convolution layer with 3 input channels, 8 output channels, kernel shape (3, 3), stride shape (2, 2), and no padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.318269Z",
          "start_time": "2021-12-10T04:02:11.313712Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "69564fc1ad54268238c4f40db99e20ce",
          "grade": false,
          "grade_id": "cell-fed411c81556bd61",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "m = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d0be78de8dc9d5a69ce3bc67e3ed313f",
          "grade": false,
          "grade_id": "cell-a2a9c5f058a63299",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "If we have an image of shape (3, 224, 224), after this convolution layer, the output shape will be (8, 111, 111). Let us verify this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.332495Z",
          "start_time": "2021-12-10T04:02:11.320316Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bfca04cefb5bb5aed5825607e448a57b",
          "grade": false,
          "grade_id": "cell-0f405cc8b70dacfa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# the first dimension is the batch size (1 in this case, since we only have one image)\n",
        "img = torch.randn(1, 3, 224, 224)\n",
        "m(img).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fd7e86da711a8414b9d52d54de9524e2",
          "grade": false,
          "grade_id": "cell-9219584b643b1938",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "In the assignment, on the other hand, we will play with sequential data. That is, each patient will be represented as a sequence of visits, and each visit will be represented as a set of diagnosis codes (a one-hot vector).\n",
        "\n",
        "Denote the number of visits for a patient as $n$, and the total number of diagnosis codes as $m$, this patient can be represented as a matrix of shape $(n, m)$. \n",
        "\n",
        "For example, let us say there are 30 diagnosis codes in total. And there is a patient with 3 visits. Then the patient can be represented as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.336663Z",
          "start_time": "2021-12-10T04:02:11.334500Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "24e63a1a69f3487e34900aba06807e7c",
          "grade": false,
          "grade_id": "cell-3dad98f2297740d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# the first dimension is the batch size (1 in this case, since we only have one patient)\n",
        "# the second dimension is the total number of diagnosis codes\n",
        "# the third dimension is the total number of visits\n",
        "patient = torch.randn(1, 30, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0cb1492fd05c41ea7a8ec0df7ed7d327",
          "grade": false,
          "grade_id": "cell-6a3468c29cf4be50",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We can then perform 1D convolution to capture the temporal information. The code below implements an 1D convolution layer with 30 input channels, 16 output channels, kernel shape 2, stride shape 1, and no padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.341935Z",
          "start_time": "2021-12-10T04:02:11.339012Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16b678c8d73cbe2ae320c8a72a83009d",
          "grade": false,
          "grade_id": "cell-a8bf485b128c7ae2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "m = nn.Conv1d(in_channels=30, out_channels=16, kernel_size=2, stride=1, padding=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "52a687236ccc963860fe4ee950a4b3ea",
          "grade": false,
          "grade_id": "cell-bdf734000abe7f27",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "After convolution, we should have a tensor of shape (16, 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.348702Z",
          "start_time": "2021-12-10T04:02:11.343952Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8897bda149d75b959744c27a0ad5d0e9",
          "grade": false,
          "grade_id": "cell-b28f04032643ff6f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "m(patient).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1e9470f29a5860ca666d3db301c002be",
          "grade": false,
          "grade_id": "cell-9d53a9b48c1ce7a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Assignment [60 points]\n",
        "\n",
        "In this assignment, you will use [MIMIC-III Demo](https://physionet.org/content/mimiciii-demo/) dataset, which contains all intensive care unit (ICU) stays for 100 patients. The task is Mortality Prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "21ca97a1b7e3f46655d8dcd31b538924",
          "grade": false,
          "grade_id": "cell-c23b3af3e6fcb189",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Load Data\n",
        "\n",
        "In the previous lab, we have preprocessed the data. Thus, for this lab, we will directly use the processed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.479581Z",
          "start_time": "2021-12-10T04:02:11.350484Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fbaaa5edc711916599624a613f06a4e0",
          "grade": false,
          "grade_id": "cell-f0553747aa0e13aa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "!ls {DATA_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fd0a1c525133be2ae4004438740d093f",
          "grade": false,
          "grade_id": "cell-3b6568c0ace0ba15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Here are the helper fuctions and CustomDataset from the previous lab. \n",
        "\n",
        "The only difference is that, starting from this lab, we will use the entire patient visit instead of only the last visit. Due to this reason, we will only keep patients with more than one visits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.486540Z",
          "start_time": "2021-12-10T04:02:11.481725Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53906d0f1c84a92784bcc4b67f235b15",
          "grade": false,
          "grade_id": "cell-658c7e525174d846",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# two helper functions\n",
        "\n",
        "TOTAL_NUM_CODES = 271\n",
        "\n",
        "\n",
        "def read_csv(filename):\n",
        "    \"\"\" reading csv from filename \"\"\"\n",
        "    data = []\n",
        "    with open(filename, \"r\") as file:\n",
        "        csv_reader = csv.DictReader(file, delimiter=',')\n",
        "        for row in csv_reader:\n",
        "            data.append(row)\n",
        "    header = list(data[0].keys())\n",
        "    return header, data\n",
        "\n",
        "\n",
        "def to_one_hot(label, num_class):\n",
        "    \"\"\" convert to one hot label \"\"\"\n",
        "    one_hot_label = [0] * num_class\n",
        "    for i in label:\n",
        "        one_hot_label[i] = 1\n",
        "    return one_hot_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.497251Z",
          "start_time": "2021-12-10T04:02:11.488743Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0833752e0e9041149f1a7faa6320991e",
          "grade": false,
          "grade_id": "cell-4c4eda236985b3ec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # read the csv\n",
        "        self._df = pd.read_csv(f'{DATA_PATH}/data.csv')\n",
        "        # split diagnosis code index by ';' and convert it to integer\n",
        "        self._df.icd9 = self._df.icd9.apply(lambda x: [int(i) for i in x.split(';')])\n",
        "        # build data dict\n",
        "        self._build_data_dict()\n",
        "        # a list of subject ids\n",
        "        self._subj_ids = list(self._data.keys())\n",
        "        # sort the subject ids to maintain a fixed order\n",
        "        self._subj_ids.sort()\n",
        "    \n",
        "    def _build_data_dict(self):\n",
        "        \"\"\" \n",
        "        build SUBJECT_ID to ADMISSION dict\n",
        "            - subject_id\n",
        "                - icd9: a list of ICD9 code index\n",
        "                - mortality: 0/1 morality label\n",
        "        \"\"\"\n",
        "        dict_data = {}\n",
        "        df = self._df.groupby('subject_id').agg({'mortality': lambda x: x.iloc[0], 'icd9': list}).reset_index()\n",
        "        for idx, row in df.iterrows():\n",
        "            subj_id = row.subject_id\n",
        "            # only keep patients with more than 1 visit\n",
        "            if len(row.icd9) >= 2:\n",
        "                dict_data[subj_id] = {}\n",
        "                dict_data[subj_id]['icd9'] = row.icd9\n",
        "                dict_data[subj_id]['mortality'] = row.mortality\n",
        "        self._data = dict_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\" return the number of samples (i.e. patients). \"\"\"\n",
        "        return len(self._subj_ids)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" generates one sample of data. \"\"\"\n",
        "        # obtain the subject id\n",
        "        subj_id = self._subj_ids[index]\n",
        "        # obtain the data dict by subject id\n",
        "        data = self._data[subj_id]\n",
        "        # convert last admission's diagnosis code index to one hot\n",
        "        x = torch.tensor([to_one_hot(visit, TOTAL_NUM_CODES) for visit in data['icd9']], dtype=torch.float32)\n",
        "        # mortality label\n",
        "        y = torch.tensor(data['mortality'], dtype=torch.float32)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.525774Z",
          "start_time": "2021-12-10T04:02:11.499034Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d98adb3cc8b250351e00560fb80dad7",
          "grade": false,
          "grade_id": "cell-64bd9fd8d521c2da",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset()\n",
        "print('Size of dataset:', len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.531747Z",
          "start_time": "2021-12-10T04:02:11.527176Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d774d9394a9ad87f2df6a6006cb7b65",
          "grade": false,
          "grade_id": "cell-5c1cb6c063c46208",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "\n",
        "split = int(len(dataset)*0.7)\n",
        "\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, test_dataset = random_split(dataset, lengths)\n",
        "\n",
        "print(\"Length of train dataset:\", len(train_dataset))\n",
        "print(\"Length of test dataset:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "267f1a0762e9b450a87f3e22c3755942",
          "grade": false,
          "grade_id": "cell-b488ab9781c9b968",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Here is an example of $x$, and $y$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.541545Z",
          "start_time": "2021-12-10T04:02:11.533133Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7e326c8f4e425c160a0a99fb3e9e8966",
          "grade": false,
          "grade_id": "cell-062f87c8a470e916",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "x, y = train_dataset[0]\n",
        "print(f'Example x (shape {x.shape}):\\n', x)\n",
        "print(f'Example y:\\n', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fbcfa7916cff14d12c59b0b25e62292",
          "grade": false,
          "grade_id": "cell-2de64c220bed55ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We can see that $x$ is of shape $(2, 271)$, which means there are $271$ diagnosis codes in total, and this patient has two visits. It is in one-hot format. A $1$ in position $i$ means that diagnosis code of index $i$ appears in the that visit.\n",
        "\n",
        "And $y$ is either $0$ or $1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4c7b530cad4b7bf74f6f77af96f1e37a",
          "grade": false,
          "grade_id": "cell-0de19a4515ddf35b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Padding [20 points]\n",
        "\n",
        "Note that the first dimension of $x$ can be different for different patients (i.e., different patients will have different number of visits). Thus we need to implement a padding function (similar to the zero padding in images).\n",
        "\n",
        "To achieve this goal, we will implement a special collage function. This collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches.\n",
        "\n",
        "For example, assume the `DataLoader` gets a list of two samples (here, assume the total number of codes is 3). \n",
        "\n",
        "```\n",
        "[ [ [0, 1, 0], [1, 0, 1] ], \n",
        "  [ [0, 0, 1], [0, 1, 1], [0, 1, 1] ] ]\n",
        "```\n",
        "\n",
        "where the first patient has two visits `[0, 1, 0]` and `[1, 0, 1]` and the second patient has three visits `[0, 0, 1]`, `[0, 1, 1]`, and `[0, 1, 1]`.\n",
        "\n",
        "The collate function `collate_fn()` is supposed to pad them into the same shape (2, 3), where 2 is the number of patients, and 3 is the maximum number of visits.\n",
        "\n",
        "```\n",
        "[ [ [0, 1, 0], [1, 0, 1], *[0, 0, 0]* ], \n",
        "  [ [0, 0, 1], [0, 1, 1],  [0, 1, 1] ] ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.548482Z",
          "start_time": "2021-12-10T04:02:11.543228Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "def collate_fn(data):\n",
        "    \"\"\"\n",
        "    TODO: Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
        "        sequences to the sample shape (max # visits, total # diagnosis codes).\n",
        "    \n",
        "    Arguments:\n",
        "        data: a list of samples fetched from `CustomDataset`\n",
        "        \n",
        "    Outputs:\n",
        "        x: a tensor of shape (# patients, total # diagnosis codes, max # visits) of type torch.float\n",
        "        y: a tensor of shape (# patients) of type torch.float\n",
        "        \n",
        "    Note that you can obtains the list of diagnosis codes and the list of mortality labels\n",
        "        using: `sequences, labels = zip(*data)`\n",
        "    \"\"\"\n",
        "\n",
        "    sequences, labels = zip(*data)\n",
        "\n",
        "    y = torch.tensor(labels, dtype=torch.float)\n",
        "    \n",
        "    num_patients = len(sequences)\n",
        "    num_visits = [patient.shape[0] for patient in sequences]\n",
        "    total_num_codes = sequences[0].shape[1]\n",
        "\n",
        "    max_num_visits = max(num_visits)\n",
        "    \n",
        "    x = torch.zeros((num_patients, total_num_codes, max_num_visits), dtype=torch.float)\n",
        "\n",
        "    for i_patient, patient in enumerate(sequences):\n",
        "        for j_visit, visit in enumerate(patient):\n",
        "            # your code here\n",
        "            raise NotImplementedError\n",
        "    \n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.560530Z",
          "start_time": "2021-12-10T04:02:11.550634Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd34743e502b3822ca541e53db290494",
          "grade": true,
          "grade_id": "cell-3e2ee044e3a07c8a",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "loader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn)\n",
        "loader_iter = iter(loader)\n",
        "x, y = next(loader_iter)\n",
        "\n",
        "assert x.dtype == torch.float\n",
        "assert y.dtype == torch.float\n",
        "\n",
        "assert x.shape[:-1] == (4, 271)\n",
        "assert y.shape == (4,)\n",
        "\n",
        "for i in range(4):\n",
        "    real_x, real_y = train_dataset[i]\n",
        "    for j in range(real_x.shape[0]):\n",
        "        visit = real_x[j]\n",
        "        got = x[i, :, j]\n",
        "        assert all(visit == got)\n",
        "        assert real_y == y[i]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5de130a1f1595f984088438d01552a31",
          "grade": false,
          "grade_id": "cell-54947dd443e4ee61",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We need to pad the sequences into the same length so that we can do batch training on GPU, which will run much faster. Or, if they have different length, we have to process them one by one. This is extremely slow, especially with a large dataset.\n",
        "\n",
        "You may also wonder will this padding add some extra noise to the dataset (because we change the number of visits for some patients). The answer is: it depends. Sometimes, padding will bring in some noise and we need to have a separate mask to remove the noise later (you will see this in the next lab).\n",
        "\n",
        "But in this lab, it does not matter. Because zero padding will not affect the convolution operation. Zero times zero is still zero (assume we do not have bias parameter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4ed4b1dab48408a4211e3af5b5f68daa",
          "grade": false,
          "grade_id": "cell-53f4b956f04397be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Data Loader\n",
        "\n",
        "Now, we can load the dataset into the data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.566002Z",
          "start_time": "2021-12-10T04:02:11.562153Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f3827264d8672c03cda07127dbd909a",
          "grade": false,
          "grade_id": "cell-c1a050941d5fba0d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# how many samples per batch to load\n",
        "batch_size = 4\n",
        "\n",
        "# prepare dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "print(\"# of train batches:\", len(train_loader))\n",
        "print(\"# of test batches:\", len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.573086Z",
          "start_time": "2021-12-10T04:02:11.567902Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7dccaef5026443cacf5ea0916ddff3df",
          "grade": false,
          "grade_id": "cell-cf668e469e5f3383",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "train_iter = iter(train_loader)\n",
        "x, y = next(train_iter)\n",
        "\n",
        "print('Shape of a batch x:', x.shape)\n",
        "print('Shape of a batch y:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6aa71441902394ddf601dbe3f4a984ee",
          "grade": false,
          "grade_id": "cell-67bd2a4540e34723",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Build the Model [20 points]\n",
        "\n",
        "Now, let us build a 1D CNN model. For each patient, the CNN model will take an input tensor of shape (# of visits, total # of codes), and produce an output tensor of 1-dim (0 for non-mortality, 1 for moratality). The detailed model architecture is shown in the table below.\n",
        "\n",
        "Layers | Configuration | Activation Function\n",
        "--- | --- | ---\n",
        "convolution | in channels 271, out channels 32, kernel size 2, stride 1, padding 0, bias False | -\n",
        "dropout | probability 0.5 | - \n",
        "fully connected | input size 32, output size 1 | Sigmoid\n",
        "\n",
        "Note that you have to set `bias=Flase` for the convolution layer. Only in this way can we ignore the noise introduced by padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.579501Z",
          "start_time": "2021-12-10T04:02:11.574694Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TODO: Build the CNN shown above.\n",
        "HINT: Consider using `nn.Conv1d`, `nn.MaxPool1d`, `nn.Dropout`, `nn.Linear`, `torch.sigmoid`.\n",
        "\"\"\"\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # DO NOT change the names\n",
        "        self.conv = None\n",
        "        self.dropout = None\n",
        "        self.fc = None\n",
        "        \n",
        "        # your code here\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        TODO: 1. pass x through the convolution layer\n",
        "              2. pass x through the dropout layer\n",
        "              3. sum x by the last dimension (i.e., visits)\n",
        "              4. pass x through the linear and sigmoid layer\n",
        "        \"\"\"\n",
        "        # your code here\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.584104Z",
          "start_time": "2021-12-10T04:02:11.581207Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "49828d6df5f2f89844c30010c2772edc",
          "grade": false,
          "grade_id": "cell-4f9ada7c74c60887",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# initialize the CNN\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.600029Z",
          "start_time": "2021-12-10T04:02:11.591707Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5223999b8c57440851e2b24380def88f",
          "grade": true,
          "grade_id": "cell-4ee174f9a07b657c",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "model = Net()\n",
        "\n",
        "assert model.conv.in_channels == 271\n",
        "assert model.conv.out_channels == 32\n",
        "assert model.conv.kernel_size == (2,)\n",
        "assert model.conv.stride == (1,)\n",
        "assert model.conv.padding == (0,)\n",
        "assert model.conv.bias is None\n",
        "assert model.fc.in_features == 32\n",
        "assert model.fc.out_features == 1\n",
        "\n",
        "train_iter = iter(train_loader)\n",
        "x, y = next(train_iter)\n",
        "output = model.forward(x)\n",
        "assert output.shape == (4, 1), \"Net() is wrong!\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6b57e302ec6503ce207a8f013692a7a6",
          "grade": false,
          "grade_id": "cell-4664f9a698dfb0ed",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that we have a network, let's see what happens when we pass in some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.608486Z",
          "start_time": "2021-12-10T04:02:11.601798Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "707e076b2b7a17603b9d198784ace7e3",
          "grade": false,
          "grade_id": "cell-fa0dcdf281213277",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "\n",
        "# Grab some data \n",
        "train_iter = iter(train_loader)\n",
        "x, y = next(train_iter)\n",
        "\n",
        "# Forward pass through the network\n",
        "output = model.forward(x)\n",
        "\n",
        "print('Input x shape:', x.shape)\n",
        "print('Output shape: ', output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "57669650616a8e8eddbf6abe743eafaf",
          "grade": false,
          "grade_id": "cell-af2e55271ae666f2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Train the Network [20 points]\n",
        "\n",
        "In this step, you will train the CNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.613266Z",
          "start_time": "2021-12-10T04:02:11.610464Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TODO: Define the loss (BCELoss), assign it to `criterion`.\n",
        "\n",
        "REFERENCE: https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
        "\"\"\"\n",
        "\n",
        "criterion = None\n",
        "\n",
        "# your code here\n",
        "raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.618100Z",
          "start_time": "2021-12-10T04:02:11.614953Z"
        },
        "deletable": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "TODO: Define the optimizer (SGD) with learning rate 0.01, assign it to `optimizer`.\n",
        "\n",
        "REFERENCE: https://pytorch.org/docs/stable/optim.html\n",
        "\"\"\"\n",
        "\n",
        "optimizer = None\n",
        "\n",
        "# your code here\n",
        "raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:11.624041Z",
          "start_time": "2021-12-10T04:02:11.620498Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4509c2beeedfe018a3c100fbb8f6213e",
          "grade": true,
          "grade_id": "cell-19ffe4a84d047d3a",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "'''\n",
        "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
        "'''\n",
        "\n",
        "assert type(criterion) is nn.modules.loss.BCELoss, \"criterion is not BCELoss!\"\n",
        "assert type(optimizer) is torch.optim.SGD, \"optimizer is not SGD!\"\n",
        "assert optimizer.param_groups[0]['lr'] == 0.01, \"learning rate is not 0.01!\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be1d0b7e0ebd3324f7feadda4f36e937",
          "grade": false,
          "grade_id": "cell-c5125efa9aa9e316",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now we can train the model. The following two cell are exactly the same as previous lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:12.018609Z",
          "start_time": "2021-12-10T04:02:11.626150Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d8293b6ab0aee29b614665d63e53c852",
          "grade": false,
          "grade_id": "cell-acf118b9d1359c94",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import *\n",
        "\n",
        "#input: Y_score,Y_pred,Y_true\n",
        "#output: accuracy, auc, precision, recall, f1-score\n",
        "def classification_metrics(Y_score, Y_pred, Y_true):\n",
        "    acc, auc, precision, recall, f1score = accuracy_score(Y_true, Y_pred), \\\n",
        "                                           roc_auc_score(Y_true, Y_score), \\\n",
        "                                           precision_score(Y_true, Y_pred), \\\n",
        "                                           recall_score(Y_true, Y_pred), \\\n",
        "                                           f1_score(Y_true, Y_pred)\n",
        "    return acc, auc, precision, recall, f1score\n",
        "\n",
        "\n",
        "#input: model, loader\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_y_true = torch.LongTensor()\n",
        "    all_y_pred = torch.LongTensor()\n",
        "    all_y_score = torch.FloatTensor()\n",
        "    for x, y in loader:\n",
        "        # pass the input through the model\n",
        "        y_hat = model(x)\n",
        "        # convert shape from [batch size, 1] to [batch size]\n",
        "        y_hat = y_hat.view(y_hat.shape[0])\n",
        "        y_pred = (y_hat > 0.5).type(torch.float)\n",
        "        all_y_true = torch.cat((all_y_true, y.to('cpu')), dim=0)\n",
        "        all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu')), dim=0)\n",
        "        all_y_score = torch.cat((all_y_score,  y_hat.to('cpu')), dim=0)\n",
        "        \n",
        "    acc, auc, precision, recall, f1 = classification_metrics(all_y_score.detach().numpy(), \n",
        "                                                             all_y_pred.detach().numpy(), \n",
        "                                                             all_y_true.detach().numpy())\n",
        "    print(f\"acc: {acc:.3f}, auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:12.036509Z",
          "start_time": "2021-12-10T04:02:12.020462Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "993ab964d2f0eb1f1d4827536d11b9a1",
          "grade": false,
          "grade_id": "cell-febc6644c84df57d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "print(\"model perfomance before training:\")\n",
        "evaluate(model, train_loader)\n",
        "evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-12-10T04:02:12.209871Z",
          "start_time": "2021-12-10T04:02:12.038136Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1f42f50db9718d22b025ef97b8b15b86",
          "grade": false,
          "grade_id": "cell-9e7554a3ce8fc984",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# number of epochs to train the model\n",
        "# feel free to change this\n",
        "n_epochs = 10\n",
        "\n",
        "# prep model for training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    train_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        \"\"\" Step 1. clear gradients \"\"\"\n",
        "        optimizer.zero_grad()\n",
        "        \"\"\"  Step 2. perform forward pass using `model`, save the output to y_hat \"\"\"\n",
        "        y_hat = model(x)\n",
        "        \"\"\" Step 3. calculate the loss using `criterion`, save the output to loss. \"\"\"\n",
        "        # convert shape from [batch size, 1] to [batch size]\n",
        "        y_hat = y_hat.view(y_hat.shape[0])\n",
        "        loss = criterion(y_hat, y)\n",
        "        \"\"\" Step 4. backward pass \"\"\"\n",
        "        loss.backward()\n",
        "        \"\"\" Step 5. optimization \"\"\"\n",
        "        optimizer.step()\n",
        "        \"\"\" Step 6. record loss \"\"\"\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "    evaluate(model, train_loader)\n",
        "    evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5e1bb6d002dfdde2e49da4549decf9a6",
          "grade": false,
          "grade_id": "cell-2e30120254908ff1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The result is bad due to very limited data. The model overfits the training data very fast.\n",
        "\n",
        "You are encouraged to try this on the whole MIMIC-III dataset. The result will be much more promising!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl4h_mooc_2111",
      "language": "python",
      "name": "dl4h_mooc_2111"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "297.1875px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}